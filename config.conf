# Shell configuration for Gemma model conversion

# --- Environment Variables ---
# These will be exported to the script's environment.
# WARNING: Storing secrets in plaintext files is a security risk.
# Consider using a secret management tool like Vault, or environment variables
# set in your shell profile or CI/CD system.
export KERAS_BACKEND="torch"
export HF_TOKEN="your huggingface token"
export KAGGLE_USERNAME="your kaggle username"
export KAGGLE_KEY="your kaggle key"

# --- Python Script Parameters ---
# These are used as command-line arguments for the export_gemma_to_hf.py script.
WEIGHTS_FILE="./content/finetuned/model.weights.json"
MODEL_SIZE="7b"
VOCAB_PATH="./content/finetuned/vocabulary.spm"
GEMMA_VERSION="1"
OUTPUT_DIR="./content/finetuned_hf"

# --- Vertex AI Deployment Parameters ---
PROJECT_ID="your_project_id"
REGION="us-central1"
BUCKET_URI="gs://your_bucket"
MODEL_NAME="gemma_7b_en"
HUGGINGFACE_MODEL_DIR="./content/finetuned_hf"
HF_MODEL_ID="google/gemma-7b"

# --- Fine-tuning Parameters ---
DATASET_NAME="databricks-dolly-15k"

# --- Inference Parameters ---
GPU_ENDPOINT_ID="4374364130153332736"
HEX_ENDPOINT_ID="4950824882456756224"