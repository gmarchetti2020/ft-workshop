# Shell configuration for Gemma model conversion

# --- Environment Variables ---
# These will be exported to the script's environment.
# WARNING: Storing secrets in plaintext files is a security risk.
# Consider using a secret management tool like Vault, or environment variables
# set in your shell profile or CI/CD system.
export HF_TOKEN="your hf token"
export KAGGLE_USERNAME="your kaggle username"
export KAGGLE_KEY="your kaggle key"

# --- For training ---
EPOCHS=2
BATCH_PER_TPU=4

# --- Python Script Parameters ---
# These are used as command-line arguments for the export_gemma_to_hf.py script.
WEIGHTS_FILE="/mnt/content/finetuned/model.weights.h5"
MODEL_SIZE="7b"
VOCAB_PATH="/mnt/content/finetuned/vocabulary.spm"
GEMMA_VERSION="1"
OUTPUT_DIR="/mnt/content/finetuned_hf"

# --- Vertex AI Deployment Parameters ---
PROJECT_ID="your project id"
REGION="your region"
BUCKET_URI="your bucket uri"
MODEL_NAME="gemma_7b_en"
HUGGINGFACE_MODEL_DIR="/mnt/content/finetuned_hf"
HF_MODEL_ID="google/gemma-7b"
FT_HF_MODEL="gimarchetti/gemma1-7b-openmath"

# --- Fine-tuning Parameters ---
DATASET_NAME="open_math_dataset"

# --- OpenAI-like chat template ---
GEMMA_CHAT="{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"

# --- GKE cluster ---
CLUSTER_NAME="your cluster name"
